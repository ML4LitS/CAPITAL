{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f284b6ba-0e09-4912-943c-64d15773a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stirunag/falconframes_env/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.2.5 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for CD\n",
      "Loaded data for OG\n",
      "Loaded data for DS\n",
      "Loaded data for GP\n",
      "Loaded data for GO\n",
      "Loaded data for EM\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from scispacy.abbreviation import AbbreviationDetector\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"/home/stirunag/work/github/CAPITAL/normalisation/en_floret_model\")\n",
    "# abbr_model = spacy.load('en_core_sci_md')\n",
    "\n",
    "# Add abbreviation detector to the abbreviation model's pipeline correctly\n",
    "# abbr_model.add_pipe(\"abbreviation_detector\", last=True)\n",
    "\n",
    "# Define mapping of annotation type to corresponding file paths\n",
    "file_mapping = {\n",
    "    'CD': ('chebi_terms.index', 'chebi_terms.pkl'),\n",
    "    'OG': ('NCBI_terms.index', 'NCBI_terms.pkl'),\n",
    "    'DS': ('umls_terms.index', 'umls_terms.pkl'),\n",
    "    'GP': ('uniprot_terms.index', 'uniprot_terms.pkl'),\n",
    "    'GO': ('go_terms.index', 'go_terms.pkl'),\n",
    "    'EM': ('em_terms.index', 'em_terms.pkl')\n",
    "}\n",
    "\n",
    "# Dictionary to hold the loaded data for each annotation type\n",
    "loaded_data = {}\n",
    "\n",
    "# Load all necessary files at the beginning\n",
    "base_path = \"/home/stirunag/work/github/CAPITAL/normalisation/dictionary/\"\n",
    "for annotation_type, (index_file, pkl_file) in file_mapping.items():\n",
    "    with open(base_path + pkl_file, \"rb\") as infile:\n",
    "        data = pickle.load(infile)\n",
    "    index = faiss.read_index(base_path + index_file)\n",
    "    loaded_data[annotation_type] = {\n",
    "        \"term_to_id\": data[\"term_to_id\"],\n",
    "        \"indexed_terms\": data[\"indexed_terms\"],\n",
    "        \"index\": index\n",
    "    }\n",
    "    print(f\"Loaded data for {annotation_type}\")\n",
    "\n",
    "# Functions for exact, fuzzy, and embedding-based matching\n",
    "def get_exact_match(term, term_dict):\n",
    "    return term_dict.get(term)\n",
    "\n",
    "def get_fuzzy_match(term, term_dict, threshold=70):\n",
    "    result = process.extractOne(term, term_dict.keys(), scorer=fuzz.ratio)\n",
    "    if result:\n",
    "        match, score = result[0], result[1]\n",
    "        if score >= threshold:\n",
    "            return term_dict[match]\n",
    "    return None\n",
    "\n",
    "def is_flat_index(index):\n",
    "    return isinstance(index, faiss.IndexFlat)\n",
    "\n",
    "def get_embedding_match(term, index, indexed_terms, term_dict, model, threshold=0.7):\n",
    "    term_vector = model(term).vector.reshape(1, -1).astype('float32')\n",
    "    faiss.normalize_L2(term_vector)\n",
    "    \n",
    "    # Handle search based on the type of index\n",
    "    if is_flat_index(index):\n",
    "        _, I = index.search(term_vector, 1)\n",
    "    else:\n",
    "        _, I = index.search(term_vector, 1)\n",
    "    \n",
    "    if I[0][0] != -1:\n",
    "        matched_term = indexed_terms[I[0][0]]\n",
    "        similarity = cosine_similarity(term_vector, model(matched_term).vector.reshape(1, -1))[0][0]\n",
    "        if similarity >= threshold:\n",
    "            return term_dict.get(matched_term, \"No Match\")\n",
    "    return None\n",
    "\n",
    "# def expand_abbreviations(term, model):\n",
    "#     doc = model(term)\n",
    "#     expanded_term = []\n",
    "#     for token in doc:\n",
    "#         if token._.long_form:  # Ensure long_form is detected by the abbreviation detector\n",
    "#             expanded_term.append(token._.long_form)\n",
    "#         else:\n",
    "#             expanded_term.append(token.text)\n",
    "#     return \" \".join(expanded_term)\n",
    "\n",
    "def map_terms(entities, annotation_type, model, scispacy_model):\n",
    "    \"\"\"Map new entities using exact, fuzzy, and embedding matches, with abbreviation fallback.\"\"\"\n",
    "    data = loaded_data[annotation_type]\n",
    "    term_dict = data[\"term_to_id\"]\n",
    "    indexed_terms = data[\"indexed_terms\"]\n",
    "    index = data[\"index\"]\n",
    "\n",
    "    mapped_entities = {}\n",
    "    for entity in entities:\n",
    "        # Step 1: Initial matching\n",
    "        # match = get_exact_match(entity, term_dict)\n",
    "        # if not match:\n",
    "        #     match = get_fuzzy_match(entity, term_dict)\n",
    "        # if not match:\n",
    "        match = get_embedding_match(entity, index, indexed_terms, term_dict, model)\n",
    "\n",
    "        # # Step 2: Abbreviation Expansion and Retry if no match\n",
    "        # if not match:\n",
    "        #     expanded_entity = expand_abbreviations(entity, scispacy_model)\n",
    "        #     if expanded_entity != entity:  # Only retry if abbreviation expanded\n",
    "        #         match = get_exact_match(expanded_entity, term_dict)\n",
    "        #         if not match:\n",
    "        #             match = get_fuzzy_match(expanded_entity, term_dict)\n",
    "        #         if not match:\n",
    "        #             match = get_embedding_match(expanded_entity, index, indexed_terms, term_dict, model)\n",
    "\n",
    "        mapped_entities[entity] = match if match else \"No Match\"\n",
    "    return mapped_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2f7107d-6df2-48a9-a8cd-b3367657882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hypertension': 'No Match', 'covid-19': 'No Match', 'Coronavirus disease': 'GO_0009614', 'T2DM': 'No Match', 'abdomen pain': 'No Match', 'fertilisation': 'GO_0009566'}\n"
     ]
    }
   ],
   "source": [
    "terms = ['hypertension', 'covid-19', 'Coronavirus disease', 'T2DM', 'abdomen pain', 'fertilisation']\n",
    "annotation_type = 'GO'\n",
    "\n",
    "# Use the updated function to map the terms\n",
    "results = map_terms(terms, annotation_type, nlp, abbr_model)\n",
    "\n",
    "# Print the mapped results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7980ca3b-631e-4759-86c5-d39789fae889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term associated with 'GO_0009614' is: obsolete disease resistance\n",
      "The term associated with 'GO_0009566' is: fertilization\n"
     ]
    }
   ],
   "source": [
    "data = loaded_data[annotation_type]\n",
    "term_dict = data[\"term_to_id\"]\n",
    "indexed_terms = data[\"indexed_terms\"]\n",
    "index = data[\"index\"]\n",
    "\n",
    "\n",
    "# Reverse the dictionary to map CUIs back to terms\n",
    "id_to_term = {v: k for k, v in term_dict.items()}\n",
    "\n",
    "# Check and print the term for each CUI found in the result dictionary\n",
    "for term, cui in results.items():\n",
    "    if cui != 'No Match':\n",
    "        original_term = id_to_term.get(cui, \"Unknown CUI\")\n",
    "        print(f\"The term associated with '{cui}' is: {original_term}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6bb38b-f087-40f5-a39e-342dc0d3eb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
